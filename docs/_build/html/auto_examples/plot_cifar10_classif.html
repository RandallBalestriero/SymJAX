

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>CIFAR10 classification &mdash; symjax 0.0.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script async="async" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-dataframe.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Speech picidae Dataset" href="datasets/plot_picidae.html" />
    <link rel="prev" title="Single-station covariance matrix" href="wavelets.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/symjax_logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../user/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../user/tutorial.html">Quick Walkthrough Tutorial of SymJAX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../user/examples.html">Examples</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Gallery</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="plot_wavelets.html">Morlet Wavelet in time and Fourier domain</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_sgd.html">Basic gradient descent (and reset)</a></li>
<li class="toctree-l2"><a class="reference internal" href="wavelets.html">Single-station covariance matrix</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">CIFAR10 classification</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="index.html#datasets">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../user/developers.html">Development</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modules/symjax.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">symjax</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/tensor.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">symjax.tensor</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/pdfs.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">symjax.tensor.pdfs</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/signal.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">symjax.tensor.signal</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/random.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">symjax.tensor.random</span></code></a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modules/data.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">symjax.data</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/initializers.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">symjax.initializers</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/layers.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">symjax.layers</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/optimizers.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">symjax.optimizers</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/schedules.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">symjax.schedules</span></code></a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">symjax</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="index.html">Gallery</a> &raquo;</li>
        
      <li>CIFAR10 classification</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/auto_examples/plot_cifar10_classif.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-plot-cifar10-classif-py"><span class="std std-ref">here</span></a>     to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="cifar10-classification">
<span id="sphx-glr-auto-examples-plot-cifar10-classif-py"></span><h1>CIFAR10 classification<a class="headerlink" href="#cifar10-classification" title="Permalink to this headline">Â¶</a></h1>
<p>example of image classification</p>
<img alt="CIFAR10 classification task" class="sphx-glr-single-img" src="../_images/sphx_glr_plot_cifar10_classif_001.svg" /><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Loading cifar10:   0%|          | 0/5 [00:00&lt;?, ?it/s]
Loading cifar10:  20%|##        | 1/5 [00:02&lt;00:08,  2.14s/it]
Loading cifar10:  40%|####      | 2/5 [00:02&lt;00:05,  1.72s/it]
Loading cifar10:  60%|######    | 3/5 [00:03&lt;00:02,  1.37s/it]
Loading cifar10:  80%|########  | 4/5 [00:03&lt;00:01,  1.01s/it]
Loading cifar10: 100%|##########| 5/5 [00:04&lt;00:00,  1.08it/s]
Loading cifar10: 100%|##########| 5/5 [00:04&lt;00:00,  1.15it/s]
Dataset cifar10 loaded in4.84s.
(32, 3, 3, 3)
(32, 32, 3, 3)
(32, 32, 3, 3)
(32, 32, 3, 3)
(32, 32, 3, 3)
(32, 32, 3, 3)
(32, 32, 3, 3)
(32, 32, 3, 3)
(32, 10)
(32, 3, 32, 32)
(32, 32, 32, 32)
(32, 32, 32, 32)
(32, 32, 32, 32)
(32, 32, 16, 16)
(32, 32, 16, 16)
(32, 32, 16, 16)
(32, 32, 16, 16)
(32, 32, 16, 16)
(32, 32, 16, 16)
(32, 32, 16, 16)
(32, 32, 16, 16)
(32, 32, 16, 16)
(32, 32, 16, 16)
(32, 32, 8, 8)
(32, 32, 8, 8)
(32, 32, 8, 8)
(32, 32, 8, 8)
(32, 32, 8, 8)
(32, 32, 8, 8)
(32, 32, 8, 8)
(32, 32, 8, 8)
(32, 32, 8, 8)
(32, 32, 8, 8)
(32, 32, 4, 4)
(32, 32, 4, 4)
(32, 32, 4, 4)
(32, 32, 4, 4)
(32, 32, 1, 1)
(32, 10)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=W, shape=(32, 3, 3, 3), dtype=None, trainable=True, scope=/) Op(name=unnamed_500, shape=(32, 3, 3, 3), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=W_1, shape=(1, 32, 1, 1), dtype=None, trainable=True, scope=/) Op(name=unnamed_516, shape=(1, 32, 1, 1), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=b, shape=(1, 32, 1, 1), dtype=None, trainable=True, scope=/) Op(name=unnamed_532, shape=(1, 32, 1, 1), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=W_2, shape=(32, 32, 3, 3), dtype=None, trainable=True, scope=/) Op(name=unnamed_548, shape=(32, 32, 3, 3), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=W_3, shape=(1, 32, 1, 1), dtype=None, trainable=True, scope=/) Op(name=unnamed_564, shape=(1, 32, 1, 1), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=b_1, shape=(1, 32, 1, 1), dtype=None, trainable=True, scope=/) Op(name=unnamed_580, shape=(1, 32, 1, 1), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=W_4, shape=(32, 32, 3, 3), dtype=None, trainable=True, scope=/) Op(name=unnamed_596, shape=(32, 32, 3, 3), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=W_5, shape=(1, 32, 1, 1), dtype=None, trainable=True, scope=/) Op(name=unnamed_612, shape=(1, 32, 1, 1), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=b_2, shape=(1, 32, 1, 1), dtype=None, trainable=True, scope=/) Op(name=unnamed_628, shape=(1, 32, 1, 1), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=W_6, shape=(32, 32, 3, 3), dtype=None, trainable=True, scope=/) Op(name=unnamed_644, shape=(32, 32, 3, 3), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=W_7, shape=(1, 32, 1, 1), dtype=None, trainable=True, scope=/) Op(name=unnamed_660, shape=(1, 32, 1, 1), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=b_3, shape=(1, 32, 1, 1), dtype=None, trainable=True, scope=/) Op(name=unnamed_676, shape=(1, 32, 1, 1), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=W_8, shape=(32, 32, 3, 3), dtype=None, trainable=True, scope=/) Op(name=unnamed_692, shape=(32, 32, 3, 3), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=W_9, shape=(1, 32, 1, 1), dtype=None, trainable=True, scope=/) Op(name=unnamed_708, shape=(1, 32, 1, 1), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=b_4, shape=(1, 32, 1, 1), dtype=None, trainable=True, scope=/) Op(name=unnamed_724, shape=(1, 32, 1, 1), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=W_10, shape=(32, 32, 3, 3), dtype=None, trainable=True, scope=/) Op(name=unnamed_740, shape=(32, 32, 3, 3), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=W_11, shape=(1, 32, 1, 1), dtype=None, trainable=True, scope=/) Op(name=unnamed_756, shape=(1, 32, 1, 1), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=b_5, shape=(1, 32, 1, 1), dtype=None, trainable=True, scope=/) Op(name=unnamed_772, shape=(1, 32, 1, 1), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=W_12, shape=(32, 32, 3, 3), dtype=None, trainable=True, scope=/) Op(name=unnamed_788, shape=(32, 32, 3, 3), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=W_13, shape=(1, 32, 1, 1), dtype=None, trainable=True, scope=/) Op(name=unnamed_804, shape=(1, 32, 1, 1), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=b_6, shape=(1, 32, 1, 1), dtype=None, trainable=True, scope=/) Op(name=unnamed_820, shape=(1, 32, 1, 1), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=W_14, shape=(32, 32, 3, 3), dtype=None, trainable=True, scope=/) Op(name=unnamed_836, shape=(32, 32, 3, 3), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=W_15, shape=(1, 32, 1, 1), dtype=None, trainable=True, scope=/) Op(name=unnamed_852, shape=(1, 32, 1, 1), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=b_7, shape=(1, 32, 1, 1), dtype=None, trainable=True, scope=/) Op(name=unnamed_868, shape=(1, 32, 1, 1), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=W_16, shape=(32, 10), dtype=None, trainable=True, scope=/) Op(name=unnamed_884, shape=(32, 10), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=b_8, shape=(10,), dtype=None, trainable=True, scope=/) Op(name=unnamed_900, shape=(10,), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
/home/vrael/SymJAX/symjax/base.py:441: UserWarning: Variable and update Variable(name=step_8, shape=(1,), dtype=None, trainable=False, scope=/) Op(name=unnamed_901, shape=(1,), dtype=float32, scope=/)are not the same dtype... attempting to cast
  &quot;are not the same dtype... attempting to cast&quot;)
Test Loss and Accu: [2.3417988  0.09995993]
Train Loss and Accu [1.4994501 0.4457026]
Test Loss and Accu: [1.5779954  0.48036858]
Train Loss and Accu [1.1472725 0.5916093]
Test Loss and Accu: [1.1623799 0.5942508]
Train Loss and Accu [1.0115813  0.64224553]

Text(0.5, 1.0, &#39;CIFAR10 classification task&#39;)
</pre></div>
</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">symjax.tensor</span> <span class="k">as</span> <span class="nn">T</span>
<span class="kn">import</span> <span class="nn">symjax</span> <span class="k">as</span> <span class="nn">sj</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>


<span class="c1"># load the dataset</span>
<span class="n">cifar10</span> <span class="o">=</span> <span class="n">sj</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cifar10</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>

<span class="c1"># some renormalization</span>
<span class="n">cifar10</span><span class="p">[</span><span class="s1">&#39;train_set/images&#39;</span><span class="p">]</span> <span class="o">/=</span> <span class="n">cifar10</span><span class="p">[</span><span class="s1">&#39;train_set/images&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">cifar10</span><span class="p">[</span><span class="s1">&#39;test_set/images&#39;</span><span class="p">]</span> <span class="o">/=</span> <span class="n">cifar10</span><span class="p">[</span><span class="s1">&#39;test_set/images&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># create the network</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">images</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">Placeholder</span><span class="p">((</span><span class="n">BATCH_SIZE</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="s1">&#39;float32&#39;</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">Placeholder</span><span class="p">((</span><span class="n">BATCH_SIZE</span><span class="p">,),</span> <span class="s1">&#39;int32&#39;</span><span class="p">)</span>
<span class="n">deterministic</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">Placeholder</span><span class="p">((</span><span class="mi">1</span><span class="p">,),</span> <span class="s1">&#39;bool&#39;</span><span class="p">)</span>

<span class="n">layer</span> <span class="o">=</span> <span class="p">[</span><span class="n">sj</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">RandomCrop</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">crop_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span>
                <span class="n">padding</span><span class="o">=</span><span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)],</span>
                <span class="n">deterministic</span><span class="o">=</span><span class="n">deterministic</span><span class="p">)]</span>

<span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">):</span>
    <span class="n">layer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sj</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">layer</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">b</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">))</span>
    <span class="n">layer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sj</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(</span><span class="n">layer</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
                                    <span class="n">deterministic</span><span class="p">))</span>
    <span class="n">layer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sj</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span><span class="n">layer</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">T</span><span class="o">.</span><span class="n">leaky_relu</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">l</span> <span class="o">%</span> <span class="mi">3</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sj</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Pool2D</span><span class="p">(</span><span class="n">layer</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>

<span class="n">layer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sj</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Pool2D</span><span class="p">(</span><span class="n">layer</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">layer</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:],</span> <span class="n">pool_type</span><span class="o">=</span><span class="s1">&#39;AVG&#39;</span><span class="p">))</span>

<span class="n">layer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sj</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">layer</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">10</span><span class="p">))</span>

<span class="c1"># each layer is itself a tensor which represents its output and thus</span>
<span class="c1"># any tensor operation can be used on the layer instance, for example</span>
<span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">layer</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">l</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>


<span class="n">loss</span> <span class="o">=</span> <span class="n">sj</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">sparse_crossentropy_logits</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">layer</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">sj</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">accuracy</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">layer</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

<span class="n">lr</span><span class="o">=</span><span class="n">sj</span><span class="o">.</span><span class="n">schedules</span><span class="o">.</span><span class="n">PiecewiseConstant</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="p">{</span><span class="mi">15</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span> <span class="mi">25</span><span class="p">:</span> <span class="mf">0.0001</span><span class="p">})</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">sj</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">lr</span><span class="p">)</span>

<span class="n">network_updates</span> <span class="o">=</span> <span class="n">sj</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">get_updates</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>

<span class="n">test</span> <span class="o">=</span> <span class="n">sj</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">])</span>

<span class="n">train</span> <span class="o">=</span> <span class="n">sj</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">,</span>
                    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">],</span> <span class="n">updates</span><span class="o">=</span><span class="p">{</span><span class="o">**</span><span class="n">opt</span><span class="o">.</span><span class="n">updates</span><span class="p">,</span>
                                                <span class="o">**</span><span class="n">network_updates</span><span class="p">})</span>

<span class="n">test_accuracy</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">L</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">sj</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">batchify</span><span class="p">(</span><span class="n">cifar10</span><span class="p">[</span><span class="s1">&#39;test_set/images&#39;</span><span class="p">],</span> <span class="n">cifar10</span><span class="p">[</span><span class="s1">&#39;test_set/labels&#39;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
                                      <span class="n">option</span><span class="o">=</span><span class="s1">&#39;continuous&#39;</span><span class="p">):</span>
        <span class="n">L</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test Loss and Accu:&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">test_accuracy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">L</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">sj</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">batchify</span><span class="p">(</span><span class="n">cifar10</span><span class="p">[</span><span class="s1">&#39;train_set/images&#39;</span><span class="p">],</span> <span class="n">cifar10</span><span class="p">[</span><span class="s1">&#39;train_set/labels&#39;</span><span class="p">],</span>
                            <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">option</span><span class="o">=</span><span class="s1">&#39;random_see_all&#39;</span><span class="p">):</span>
        <span class="n">L</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Train Loss and Accu&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">lr</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">test_accuracy</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epochs&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;CIFAR10 classification task&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 3 minutes  31.527 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-plot-cifar10-classif-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/d120aba9e0c75cf8a5005dfe1b60d70c/plot_cifar10_classif.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_cifar10_classif.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/f87d2eccb8b247ecf8c160aba657fd1e/plot_cifar10_classif.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_cifar10_classif.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="datasets/plot_picidae.html" class="btn btn-neutral float-right" title="Speech picidae Dataset" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="wavelets.html" class="btn btn-neutral float-left" title="Single-station covariance matrix" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Randall Balestriero

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>